\chapter{Introduction}
The idea of creating mass-produced self-driving, or autonomous, vehicle has seen more and more interest from researchers and car manufacturers in the last few years.

The idea of inventing an autonomous car is not a new thing with people having dreamt up future societies where people would focus on other things while their cars drove them from A to B\todo{cite. }. In the last decade these ideas are finally being realised with research projects such as Google's Self Driving Car Project and earlier research projects such as Carnegie Melon and Stanfords entries into the DARPA Grand Challenge. \todo{cite.} 

\newpar Certain ethical issues arise with autonomous vehicles, however. Since autonomous vehicles are programmed to handle preferably every possible scenario on the road in advance, autonomous vehicles present ethical dilemmas that human drivers in non-autonomous vehicles do not. 

\newpar People are rarely blamed for acting according to their instinct in life-threatening vehicle collisions, even if this means that they inadvertently make decisions that have fatal consequences for other people. 

These decisions have to be programmed into autonomous vehicles in advance in order to make the "right" choice, should they occur. 
This raises interesting questions, such as; who should be blamed for an autonomous vehicle hitting, and possibly killing, one person over another? Should we even program autonomous vehicles to be able to select the "preferable" target of collision, or would it be better to not do any selection at all and make the vehicle choose some random behaviour in a critical situation?   

\todo{Write about research question.}