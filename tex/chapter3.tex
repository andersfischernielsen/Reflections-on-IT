\chapter{Ethics of Autonomous Vehicles}

Initially, autonomous vehicles might not present many ethical dilemmas, but as Moor says: 

\begin{quote}	
	\textquote{Although a problem in computer ethics may seem clear initially, a little reflection reveals a conceptual muddle. What is needed in such cases is an analysis that provides a coherent conceptual framework within which to formulate a policy for action.} \cite{moor1985computer}
\end{quote}

\noindent Defining and designing algorithms that will guide Autonomous Vehicles (AVs) when put in moral dilemmas is very challenging. So-called moral algorithms should accomplish and be evaluated against potentially incompatible objectives \cite{10.2307/2027067}:

\begin{itemize}
	\item \textbf{Be consistent:} Take predictable measures in critical situations.
	\item \textbf{Not cause public outrage:} Act according to the moral principles of society.
	\item \textbf{Not discourage buyers:} Make the public comfortable buying and using AVs thereby allowing the widespread use of AVs. 
\end{itemize}

\newpar Accepting autonomous vehicles into society presents some interesting ethical dilemmas. Because completely autonomous vehicles have only been on the road for a few years, no policy for action has been formulated regarding these vehicles. An example illustrates where debate can be held regarding autonomous vehicles is the example where you are sitting in your autonomous car, going to work. In front of you is a flatbed truck with a heavy load tied to the truck. On your immediate right is a motorcyclist and on your left is an SUV with a family of four in it. Your autonomous car is keeping a safe distance to the truck, so that if it breaks suddenly, you could stop. 

Then the cable on the truck snaps, and the heavy load falls onto the road immediately in front of you. Your car could not predict this, it merely sees a new obstacle in front of you. Avoiding it without injuring you is impossible. Your car could choose to swerve, hitting either the motorcyclist or the SUV. Hitting the SUV might injure both you and the family inside, but hitting the motorcyclist would not injure you, instead it would injure the motorcyclist severely.

I will use this ethical dilemma for the following discussion of how to view the ethical issues involved. 

These situations \textit{can} occur, even though they may happen extremely rarely. The possibility of this happening forces us to reason about the validity of having autonomous vehicles, and who should be made responsible for any accidents that occur, if we can even hold anyone responsible. 

\newpar According to utilitarianists, no matter the ethical issues involved in possible critical situations involving autonomous cars, having autonomous cars will always be ethically sound, since autonomous cars, even with many critical situations, will save more lives overall. Even if the act of selecting individuals to hit if it is unavoidable, the end result - drastically lowering the current amount of people killed in accidents - will maximise the well-being of humans. Therefore developing autonomous cars, as long as this saves more lives, will be a good thing. In the end, an autonomous driver will outperform a human driver, and therefore save more lives. No matter the implications, having autonomous drivers will be better. 

If viewing possible ethical dilemmas involving autonomous cars in accidents as an utilitarianist, placing the responsibility either of who should be held responsible for accidents or determining whether to hit the motorcyclist, injure yourself or hit the SUV, would simply mean analysing the consequences of the hitting or blaming all possible actors, and choosing the one that brings the least human harm.

\newpar According to deontologicalists, the car should never choose to hit anyone, since deliberately hitting another person is wrong, and the entire act would therefore be wrong. Though, if the hitting of a person is seen as an accident then it is unavoidable, and would happen either way. Therefore it is hard to argue that the action is bad, since it is unavoidable.  

\newpar Another argument for allowing the selection of a person to hit with the car, would be that since accidents happen, and that some number of people every year would be hit, whether it's this person or another person deos not matter. The person hit is just hit one of many accidents that happen every year, and the person is therefore not a victim of specific targeting, and therefore not a victim at all.

\newpar Ducking harm, the act of transferring harm to another person by stepping out of the dangerous situation, when the person is left behind, is generally considered better than explicitly sacrificing the other person, by placing him/her in harms way instead of one self \footnote{\cite{10.2307/2027067}}.
This would seem to change the act of a car avoiding hitting five people, and instead hitting one person into being bad. Now the single person has been explicitly sacrificed, thereby transferring harm from the passengers of the car, which would be deemed worse than simply "doing nothing" and hitting the five people. 

\newpar The non-identity problem comes into play when discussing the issue of bringing autonomous vehicles into the world that possibly have to choose to hit, and possibly kill, people. The existence of this car would be flawed, but choosing to bring a non-autonomous car into this world would not result in the same existence. Not bringing the car into this world would make life worse for future or existing people, since these people would be involved in possibly lethal accidents they otherwise would not have.    

\newpar Giving designers and auto-manufacturers the responsibility of determining whether to hit or not hit a person is unrealistic, due to the nature of these situations. Choosing to always injure the driver of the car or always hitting the oldest person registered by the car is not really an option, since the situations in which these choices have to be made change. 