\chapter{Discussion of Ethical Views and their Application on Autonomous Vehicles}

Using the definitions from the previous section, I will in this section analyse the ethical dilemmas that might occur with autonomous vehicles, and set these definitions up against each-other. On the first look, autonomous vehicles being part of our everyday life might not present many ethical dilemmas, but as Moor says: 

\begin{quote}	
	\textquote{Although a problem in computer ethics may seem clear initially, a little reflection reveals a conceptual muddle. What is needed in such cases is an analysis that provides a coherent conceptual framework within which to formulate a policy for action.} \cite{moor1985computer}
\end{quote}

\noindent Defining and designing algorithms that will guide Autonomous Vehicles (AVs) when put in moral dilemmas is very challenging. So-called moral algorithms should accomplish and be evaluated against potentially incompatible objectives \cite{10.2307/2027067}:

\begin{itemize}
	\item \textbf{Be consistent:} Take predictable measures in critical situations.
	\item \textbf{Not cause public outrage:} Act according to the moral principles of society.
	\item \textbf{Not discourage buyers:} Make the public comfortable buying and using AVs thereby allowing the widespread use of AVs. 
\end{itemize}

\newpar Accepting autonomous vehicles into society presents some interesting ethical dilemmas. Because completely autonomous vehicles have only been on the road for a few years, no policy for action has been formulated regarding these vehicles. An example of an ethical dilemma would be yourself sitting in your autonomous car, going to work. In front of you is a flatbed truck with a heavy load tied to the truck. On your immediate right is a motorcyclist and on your left is an SUV with a family of four in it. Your autonomous car is keeping a safe distance to the truck, so that if it breaks suddenly, you could stop. 

Then the cable on the truck snaps, and the heavy load falls onto the road immediately in front of you. Your car could not predict this, it merely sees a new obstacle in front of you. Avoiding it without injuring you is impossible. Your car could choose to swerve, hitting either the motorcyclist or the SUV. Hitting the SUV might injure both you and the family inside, but hitting the motorcyclist would not injure you, instead it would injure the motorcyclist severely.

I will use this ethical dilemma for the following discussion of how to view the ethical issues involved. 

These situations \textit{can} occur, even though they may happen extremely rarely. The mere possibility of this happening forces us to reason about the decisions autonomous vehicles must make, and who should be made responsible for any accidents that occur, if it is even possible to hold anyone responsible. 

\section{An Utilitarian View}
\newpar According to utilitarianists, no matter the ethical dilemma involved in possible critical situations involving autonomous cars, simply just having autonomous cars will always be ethically sound, since autonomous cars will save lives. Provided that an autonomous vehicle must choose to hit a person, the end result will still drastically lower the current amount of people killed in accidents, and therefore maximise the well-being of humans. 

Provided the ethical dilemma described, a car will have to choose whether to injure a person. The utilitarianist view gives that the action increasing utility - saving the highest amount of people - is the right action to take. 

Utilitarianism does not provide a sound answer to who is to blame for the possible death of the person hit. An extreme view is that no-one is to blame, since the action was not wrong. By saving the minivan with the family of four, and therefore either sacrificing the passenger of the car, the maximum utility has been reached. 

\newpar Why not hit the motorcyclist? \textit{Ducking harm}, the act of transferring harm to another person by stepping out of the dangerous situation, when the person is left behind, is generally considered more right, than explicitly sacrificing the other person by placing him/her in harms way instead of oneself \cite{10.2307/2027067}. By hitting the motorcyclist, harm is explicitly transferred to this person, thereby being a worse act.   
On the other hand, this would seem to change the act of a car avoiding hitting five people and instead hitting one person on the sidewalk, into being a bad act. Suddenly the single person has had harm transferred explicitly to him from the passengers of the car, which would be deemed worse than simply "doing nothing" and hitting the five people. This conflict with the utilitarian view, and a new ethical dilemma is thereby introduced.     

\section{A Deontologist View}
\newpar According to deontologicalists, an autonomous vehicle should be programmed to never hit any people. Deliberately choosing to hitting another person is a morally wrong act, no matter the outcome. Letting the passengers of the car crash in order to not explicitly target people, would be the right action. 

On the other hand, if hitting a person is seen as an accident that naturally occurs when driving, then it is unavoidable, and would happen either way, no matter whether the autonomous car is involved or not. With this view, the action of hitting a person can not be bad, since it would happen regardless. 

According to this logic there \textit{is} no victim, since the person hit is just one of many accidents that happen every year, and there is therefore no-one to blame.

\section{The Non-identity Problem}
\newpar The non-identity problem comes into play when discussing the issue of bringing autonomous vehicles into the world that possibly have to choose to hit, and possibly kill, people. The existence of this car would be flawed, but choosing to bring a non-autonomous car into this world would not result in the same existence. 

Furthermore, not bringing the car into this world would make life worse for future or existing people, since these people would be involved in possibly lethal accidents they otherwise would not have.

\newpar It could therefore be argued that bringing autonomous vehicles that have to hit, and possibly kill, people into this world is the right thing to do. 
With this view, no-one is to blame, since the situation is flawed. Not bringing possibly killing autonomous cars into the world would make current and future people worse of, and is therefore not an alternative. Blame can therefore not be placed on anyone in particular, since the ethical issues involved prohibit this. 

\newpar Furthermore, giving designers and auto-manufacturers the responsibility of determining whether to hit or not hit a person is unrealistic, due to the nature of these situations. A designer or programmer cannot design an algorithm that will be satisfying in every situation, due to the complicated nature of these situations. Choosing the same course of action will not always make sense. Responsibility for the actions taken by autonomous vehicles can therefore not be placed here, either.   

\section{Are We Ready for Utilitarianist Cars?}
Looking at ethical dilemmas and trying to answer them using ethical theories might not provide a satisfactory answer to how the requirements of the algorithms of autonomous vehicles should be fulfilled, as demonstrated by researchers Jean{-}Fran{\c{c}}ois Bonnefon and Azim Shariff and Iyad Rahwan, when looking at the presenting the idea of an utilitarian car for 300 people. \cite{DBLP:journals/corr/BonnefonSR15}
Their research provided rather interesting results. Most people thought that an autonomous vehicle should make the utilitarian decision, and always harm as few people as possible. Furthermore, they also thought that the car should injure the passenger of the car instead of a random passer-by while saving more people from being hit, satisfying the deontological view that no bad action can be taken by the car. 

Surprisingly, the people asked then said they would not purchase such car. An algorithm making actions according to the opinion of the people is therefore not satisfactory either, illustrating that a single answer to the presented ethical dilemmas is impossible to find. 

Automated cars promise great benefits and unforeseen effects that are hard to predict. Autonomous vehicles seem to be coming either way, with progress happening in big increments yearly. Change is unavoidable and not a bad thing, but new harms should be avoided where possible. This is the role of ethics: it can help us get a nicer future life, or it could wreck us if we do not watch out.

As Moor fittingly said: 
\begin{quote}
	\textquote{On my view, computer ethics is a dynamic and complex field of study which considers the relationships among facts, conceptualizations, policies and values with regard to constantly changing computer technology. Computer ethics is not a fixed set of rules which one shellacs and hangs on the wall.}
\end{quote}

The ethical dilemmas presented by the introduction of autonomous vehicles do not allow for clear-cut answers, telling us how to design algorithms controlling the vehicles. It is impossible to give a clear preemptive answer as to who should take the blame for actions autonomous vehicles take.