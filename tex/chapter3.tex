\chapter{Discussion of Ethical Views and their Application on Autonomous Vehicles}

Using the definitions from the previous section, I will in this section analyse the ethical dilemmas that might occur with autonomous vehicles, and set these definitions up against each-other. On the first look, autonomous vehicles being part of our everyday life might not present many ethical dilemmas, but as Moor says: 

\begin{quote}	
	\textquote{Although a problem in computer ethics may seem clear initially, a little reflection reveals a conceptual muddle. What is needed in such cases is an analysis that provides a coherent conceptual framework within which to formulate a policy for action.} \cite{moor1985computer}
\end{quote}

\noindent Defining and designing algorithms that will guide Autonomous Vehicles (AVs) when put in moral dilemmas is very challenging. So-called moral algorithms should accomplish and be evaluated against potentially incompatible objectives \cite{10.2307/2027067}:

\begin{itemize}
	\item \textbf{Be consistent:} Take predictable measures in critical situations.
	\item \textbf{Not cause public outrage:} Act according to the moral principles of society.
	\item \textbf{Not discourage buyers:} Make the public comfortable buying and using AVs thereby allowing the widespread use of AVs. 
\end{itemize}

\newpar Accepting autonomous vehicles into society presents some interesting ethical dilemmas. Because completely autonomous vehicles have only been on the road for a few years, no policy for action has been formulated regarding these vehicles. An example of an ethical dilemma would be yourself sitting in your autonomous car, going to work. In front of you is a flatbed truck with a heavy load tied to the truck. On your immediate right is a motorcyclist and on your left is an SUV with a family of four in it. Your autonomous car is keeping a safe distance to the truck, so that if it breaks suddenly, you could stop. 

Then the cable on the truck snaps, and the heavy load falls onto the road immediately in front of you. Your car could not predict this, it merely sees a new obstacle in front of you. Avoiding it without injuring you is impossible. Your car could choose to swerve, hitting either the motorcyclist or the SUV. Hitting the SUV might injure both you and the family inside, but hitting the motorcyclist would not injure you, instead it would injure the motorcyclist severely.

I will use this ethical dilemma for the following discussion of how to view the ethical issues involved. 

These situations \textit{can} occur, even though they may happen extremely rarely. The mere possibility of this happening forces us to reason about the decisions autonomous vehicles must make, and who should be made responsible for any accidents that occur, if it is even possible to hold anyone responsible. 

\section{An Utilitarian View}
\newpar According to utilitarianists, no matter the ethical dilemma involved in possible critical situations involving autonomous cars, simply just having autonomous cars will always be ethically sound, since autonomous cars will save lives. Provided that an autonomous vehicle must choose to hit a person, the end result will still drastically lower the current amount of people killed in accidents, and therefore maximise the well-being of humans. 

Provided the ethical dilemma described, a car will have to choose whether to injure a person. The utilitarianist view gives that the action increasing utility - saving the highest amount of people - is the right action to take. 

Utilitarianism does not provide a sound answer to who is to blame for the possible death of the person hit. An extreme view is that no-one is to blame, since the action was not wrong. By saving the minivan with the family of four, and therefore either sacrificing the passenger of the car, the maximum utility has been reached. 

\newpar Why not hit the motorcyclist? \textit{Ducking harm}, the act of transferring harm to another person by stepping out of the dangerous situation, when the person is left behind, is generally considered more right, than explicitly sacrificing the other person by placing him/her in harms way instead of oneself \cite{10.2307/2027067}. By hitting the motorcyclist, harm is explicitly transferred to this person, thereby being a worse act.   
On the other hand, this would seem to change the act of a car avoiding hitting five people and instead hitting one person on the sidewalk, into being a bad act. Suddenly the single person has had harm transferred explicitly to him from the passengers of the car, which would be deemed worse than simply "doing nothing" and hitting the five people. This conflict with the utilitarian view, and a new ethical dilemma is thereby introduced.     

\section{A Deontologist View}
\newpar According to deontologicalists, an autonomous vehicle should be programmed to never hit any people. Deliberately choosing to hitting another person is a morally wrong act, no matter the outcome. Letting the passengers of the car crash in order to not explicitly target people, would be the right action. 

On the other hand, if hitting a person is seen as an accident that naturally occurs when driving, then it is unavoidable, and would happen either way, no matter whether the autonomous car is involved or not. With this view, the action of hitting a person can not be bad, since it would happen regardless. 

According to this logic there \textit{is} no victim, since the person hit is just one of many accidents that happen every year, and there is therefore no-one to blame.

\section{The Non-identity Problem}
\newpar The non-identity problem comes into play when discussing the issue of bringing autonomous vehicles into the world that possibly have to choose to hit, and possibly kill, people. The existence of this car would be flawed, but choosing to bring a non-autonomous car into this world would not result in the same existence. 

Furthermore, not bringing the car into this world would make life worse for future or existing people, since these people would be involved in possibly lethal accidents they otherwise would not have.

\newpar It could therefore be argued that bringing autonomous vehicles, that have to hit, and possibly kill, people into this world is the right thing to do. 

\newpar Giving designers and auto-manufacturers the responsibility of determining whether to hit or not hit a person is unrealistic, due to the nature of these situations. 

Choosing to always injure the driver of the car or always hitting the oldest person registered by the car is not really an option, since the situations in which these choices have to be made change. 


\section{Are We Ready for Utilitarianist Cars}